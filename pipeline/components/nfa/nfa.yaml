$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
type: command

# General information about the component
name: nfa_inference
display_name: Forced alignment  inference
description: A template component to run inference on Forced Alignmend based on Viterbi algorithm by Nvidia.
tags:
  author: Antonio Zarauz Moreno
  version: '1.0'

# Inputs and outputs
inputs:
  input_path:
    type: uri_folder
    optional: false
  input_asr_path:
    type: uri_folder
    optional: false
  fa_model_name:
    type: string
    default: 'stt_es_fastconformer_hybrid_large_pc'
    optional: true
  fa_batch_size:
    type: integer
    default: 32
    min: 1
    max: 128
    optional: true
outputs:
  output_path:
    type: uri_folder

# The source code path of it's defined in the code section and when the
# component is run in cloud, all files from that path will be uploaded
# as the snapshot of this component
code: ./

# Environment takes care of source image and dependencies
# https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-environments-v2?view=azureml-api-2&tabs=cli
environment:
  image: nfa_env:1

# Cluster instance
compute: azureml:gpu-cluster

# Distribution type
distribution:
  type: pytorch
  process_count_per_instance: 1 # Number of nodes per instance

# How many VMs we need
resources:
  instance_count: 1 # Number of instances to create

# The command section specifies the command to execute while running
# this component
# When the input is set as optional = true, you need use $[[]] to embrace
# the command line with inputs.
command: python ./main.py --input_path ${{inputs.input_path}} --input_asr_path ${{inputs.input_asr_path}} $[[--fa_model_name ${{inputs.fa_model_name}}]] $[[--fa_batch_size ${{inputs.fa_batch_size}}]] --output_path ${{outputs.output_path}}