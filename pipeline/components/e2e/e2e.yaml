$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
type: command

# General information about the component
name: e2e_transcription
display_name: End-to-end transcription
description: A template component to run inference ona series of tools to provide high-quality transcriptions.
tags:
  author: Antonio Zarauz Moreno
  version: '1.0'

# Inputs and outputs
inputs:
  input_path:
    type: uri_folder
    optional: false
  keyvault_name:
    type: string
    optional: false
  secret_name:
    type: string
    optional: false
  vad_threshold:
    type: number
    min: 0.1
    max: 0.9
    default: 0.5
    optional: true
  min_speech_duration_ms:
    type: integer
    min: 0
    max: 2000
    default: 250
    optional: true
  min_silence_duration_ms:
    type: integer
    min: 0
    max: 2000
    default: 100
    optional: true
  speech_pad_ms:
    type: integer
    min: 0
    max: 1000
    default: 400
    optional: true
  use_onnx_vad:
    type: boolean
    default: true
    optional: true
  demucs_model:
    type: string
    default: 'htdemucs'
    optional: true
  asr_model_name:
    type: string
    default: "openai/whisper-large-v2"
    optional: true
  asr_compute_type:
    type: string
    default: 'float16'
    optional: true
  asr_chunk_length_s:
    type: integer
    min: 10
    max: 60
    default: 30
    optional: true
  asr_batch_size:
    type: integer
    min: 1
    max: 128
    default: 16
    optional: true
  fa_model_name:
    type: string
    default: "stt_en_fastconformer_hybrid_large_pc"
    optional: true
  fa_batch_size:
    type: integer
    min: 1
    max: 128
    default: 16
    optional: true
  event_type:
    type: string
    enum: ['meeting', 'telephonic']
    default: 'telephonic'
    optional: true
  max_num_speakers:
    type: integer
    default: 2
    min: 1
    max: 8
    optional: true
  max_words_in_sentence:
    type: integer
    default: 40
    min: 10
    max: 100
    optional: true
outputs:
  output_path:
    type: uri_folder

# The source code path of it's defined in the code section and when the
# component is run in cloud, all files from that path will be uploaded
# as the snapshot of this component
code: ./

# Environment takes care of source image and dependencies
# https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-environments-v2?view=azureml-api-2&tabs=cli
environment:
  image: asr_env:1

# Cluster instance
compute: azureml:gpu-cluster

# Distribution type
distribution:
  type: pytorch
  process_count_per_instance: 1 # Number of nodes per instance

# How many VMs we need
resources:
  instance_count: 1 # Number of instances to create

# The command section specifies the command to execute while running
# this component
# When the input is set as optional = true, you need use $[[]] to embrace
# the command line with inputs.
command: python ./main.py --input_path ${{inputs.input_path}} /
                          --keyvault_name ${{inputs.keyvault_name}} /
                          --secret_name ${{inputs.secret_name}} /
                          $[[--vad_threshold ${{inputs.vad_threshold}}]] /
                          $[[--min_speech_duration_ms ${{inputs.min_speech_duration_ms}}]] /
                          $[[--min_silence_duration_ms ${{inputs.min_silence_duration_ms}}]] /
                          $[[--speech_pad_ms ${{inputs.speech_pad_ms}}]] /
                          $[[--use_onnx_vad ${{inputs.use_onnx_vad}}]] /
                          $[[--demucs_model ${{inputs.demucs_model}}]] /
                          $[[--asr_model_name ${{inputs.asr_model_name}}]] /
                          $[[--asr_compute_type ${{inputs.asr_compute_type}}]] /
                          $[[--asr_chunk_length_s ${{inputs.asr_chunk_length_s}}]] /
                          $[[--asr_batch_size ${{inputs.asr_batch_size}}]] /
                          $[[--fa_model_name ${{inputs.fa_model_name}}]] /
                          $[[--fa_batch_size ${{inputs.fa_batch_size}}]] /
                          $[[--event_type ${{inputs.event_type}}]] /
                          $[[--max_num_speakers ${{inputs.max_num_speakers}}]] /
                          $[[--max_words_in_sentence ${{inputs.max_words_in_sentence}}]] /
                          --output_path ${{outputs.output_path}}