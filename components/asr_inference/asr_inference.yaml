$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
type: command

# General information about the component
name: asr_inference
display_name: ASR inference
description: A template component to run inference on Whisper with forcing alignment from Wav2Vec2.
tags:
  author: IA-Cognitive

# Inputs and outputs
inputs:
  input_path:
    type: uri_folder
    optional: false
  whisper_model_name:
    type: string
    default: large-v2
    optional: true
  vad_threshold:
    type: number
    min: 0.0
    max: 1.0
    default: 0.35
    optional: true
  no_speech_threshold:
    type: number
    min: 0.0
    max: 1.0
    default: 0.5
    optional: true
  language_code:
    type: string
    default: es
    optional: true
outputs:
  output_path:
    type: uri_folder

# The source code path of it's defined in the code section and when the
# component is run in cloud, all files from that path will be uploaded
# as the snapshot of this component
code: ./

# Where to run it
environment:
  build:
    path: ./docker
compute: azureml:gpu-cluster # This is a 1xTeslaK80 VM

# How to run it
distribution:
  type: pytorch
  process_count_per_instance: 1 # Number of GPUs per instance
resources:
  instance_count: 1 # Number of instances to create

# The command section specifies the command to execute while running
# this component
# When the input is set as optional = true, you need use $[[]] to embrace
# the command line with inputs.
command: python ./main.py --input_path ${{inputs.input_path}} $[[--whisper_model_name ${{inputs.whisper_model_name}}]] $[[--vad_threshold ${{inputs.vad_threshold}}]] $[[--no_speech_threshold ${{inputs.no_speech_threshold}}]] $[[--language_code ${{inputs.language_code}}]] --output_path ${{outputs.output_path}}